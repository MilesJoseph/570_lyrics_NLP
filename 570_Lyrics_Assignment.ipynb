{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "from boto3.session import Session \n",
    "import pandas as pd \n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re  \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "Config = configparser.ConfigParser()\n",
    "Config.read_file(open('/Users/milesklingenberg/Documents/Personal/AWS_Keys'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = Config.get('AWS', 'AWS_ACCESS_KEY_ID')\n",
    "SECRET = Config.get('AWS', 'Secret')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are storing the data on AWS. \n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                   )\n",
    "s3client = boto3.client('s3', \n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just a list to look at my available buckets for naming conventions. \n",
    "#for bucket in s3.buckets.all():\n",
    "    #print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = s3client.get_object(Bucket = 'lyrics-for-570', Key = 'lyrics.csv')\n",
    "\n",
    "#If you want to read this yourself just replace the pr.read_csv to the local path for your data, otherwise \n",
    "#this s3 bucket is public. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = pd.read_csv(file['Body'])\n",
    "lyrics = pd.DataFrame(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 362237 entries, 0 to 362236\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   index   362237 non-null  int64 \n",
      " 1   song    362235 non-null  object\n",
      " 2   year    362237 non-null  int64 \n",
      " 3   artist  362237 non-null  object\n",
      " 4   genre   362237 non-null  object\n",
      " 5   lyrics  266557 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 16.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Want to look at the structure of our data set. \n",
    "print(lyrics.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will probably need to run this on a virtual server in order to do ETL and \n",
    "#modeling for \n",
    "\n",
    "#When we are ready to deploy this model we will want to remove this portion and \n",
    "#extend efforts to whole data set. \n",
    "\n",
    "lyrics = lyrics[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                    song  year           artist genre  \\\n",
      "0      0               ego-remix  2009  beyonce-knowles   Pop   \n",
      "1      1            then-tell-me  2009  beyonce-knowles   Pop   \n",
      "2      2                 honesty  2009  beyonce-knowles   Pop   \n",
      "3      3         you-are-my-rock  2009  beyonce-knowles   Pop   \n",
      "4      4           black-culture  2009  beyonce-knowles   Pop   \n",
      "5      5  all-i-could-do-was-cry  2009  beyonce-knowles   Pop   \n",
      "6      6      once-in-a-lifetime  2009  beyonce-knowles   Pop   \n",
      "7      7                 waiting  2009  beyonce-knowles   Pop   \n",
      "8      8               slow-love  2009  beyonce-knowles   Pop   \n",
      "9      9   why-don-t-you-love-me  2009  beyonce-knowles   Pop   \n",
      "\n",
      "                                              lyrics  \n",
      "0  Oh baby, how you doing?\\nYou know I'm gonna cu...  \n",
      "1  playin' everything so easy,\\nit's like you see...  \n",
      "2  If you search\\nFor tenderness\\nIt isn't hard t...  \n",
      "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...  \n",
      "4  Party the people, the people the party it's po...  \n",
      "5  I heard\\nChurch bells ringing\\nI heard\\nA choi...  \n",
      "6  This is just another day that I would spend\\nW...  \n",
      "7  Waiting, waiting, waiting, waiting\\nWaiting, w...  \n",
      "8  [Verse 1:]\\nI read all of the magazines\\nwhile...  \n",
      "9  N-n-now, honey\\nYou better sit down and look a...  \n"
     ]
    }
   ],
   "source": [
    "#switching variables here as it takes awhile to load in the data each time. \n",
    "lyrics_1 = lyrics\n",
    "#We can also take a peak at the data \n",
    "print(lyrics.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#typically we could sub values where there are Null, but for lyrics this is obviously not possible, so we \n",
    "#will remove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We know that the length of our data is 30k \n",
    "#lyrics_1 = lyrics_1.dropna()\n",
    "\n",
    "#You could label based on the artist and the propensity for offensiveness. \n",
    "#Something that was annoying is that the csv actually had \"nan\" as an entry as opposed \n",
    "#to actually nan value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function does all of the preprocessing steps for us. \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "lyrics_1['lyrics_cleaned_total']=lyrics_1['lyrics'].map(lambda s:preprocess(s)) \n",
    "\n",
    "##lambda exampe.  lyrics['test']= lyrics['lyrics'].apply(lambda x: 1 if len(x) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lyrics_1.drop(lyrics_1.columns[len(lyrics_1.columns)-1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
